{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "12akwXGaMDAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "_auF-N3R6jot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "PX-okYJJMII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dictionary of {filename: embedding_vector}\n",
        "with open(\"embeddings.pkl\", \"rb\") as f:\n",
        "    embeddings = pickle.load(f)"
      ],
      "metadata": {
        "id": "zDcj2adn6tfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87qt4Fn06Smf"
      },
      "outputs": [],
      "source": [
        "# access one entry\n",
        "print(len(embeddings))                # number of samples\n",
        "print(list(embeddings.keys())[:5])    # filenames\n",
        "vec = embeddings[\"00001.jpg\"]        # numpy array shape (512,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to torch tensor when used\n",
        "emb_target = torch.tensor(vec).unsqueeze(0).cuda()  # shape [1,512]\n",
        "print(emb_target.shape)"
      ],
      "metadata": {
        "id": "vbQEG86A6iRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160,160)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "yxs07iVJ6iKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_00001 = Image.open(\"00001.jpg\").convert(\"RGB\")\n",
        "x_00001 = transform(img_00001).unsqueeze(0).to(device)\n",
        "img_00002 = Image.open(\"00002.jpg\").convert(\"RGB\")\n",
        "x_00002 = transform(img_00002).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "QMaTV-hvE1pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_00001 = model(x_00001*2-1).detach().cpu().numpy()[0]\n",
        "emb_00002 = model(x_00002*2-1).detach().cpu().numpy()[0]"
      ],
      "metadata": {
        "id": "HxMver7fFD0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_00001"
      ],
      "metadata": {
        "id": "Gqp1iBVxQCZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_00002"
      ],
      "metadata": {
        "id": "09DzTpV2QHRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_00001.size, x.shape"
      ],
      "metadata": {
        "id": "JrgAt_TXGXr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_data = np.random.randint(\n",
        "    0, 256,\n",
        "    size=(256, 256, 3),\n",
        "    dtype=np.uint8\n",
        ")\n",
        "random_img = Image.fromarray(random_data, 'RGB')"
      ],
      "metadata": {
        "id": "Nxv4pFgJOO42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img"
      ],
      "metadata": {
        "id": "M4F6F9ZROc14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_tensor = transform(random_img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jDlqOWknGc9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_emb = model(random_image_tensor*2-1).detach().cpu().numpy()[0]"
      ],
      "metadata": {
        "id": "nUxUWx2VM4tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_emb.shape, emb_00001.shape"
      ],
      "metadata": {
        "id": "4Lh4aCv_OqPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_dist = cosine(random_image_emb, emb_00001)\n",
        "cosine_dist"
      ],
      "metadata": {
        "id": "1ArKnrtaPCw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the random image has no relationship with the face embedding, the distance is close to 1"
      ],
      "metadata": {
        "id": "qMKfXPkwQp5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_dist = cosine(emb_00001, emb_00002)\n",
        "cosine_dist"
      ],
      "metadata": {
        "id": "FNYvEvDpPfDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the 2 face embeddings are intentionally different, their distance is closer to 2 which means closer to opposite."
      ],
      "metadata": {
        "id": "afKlTpQzQz2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from PIL import Image\n",
        "\n",
        "# Ensure random_image_tensor is on the correct device and requires grad\n",
        "random_image_tensor = random_image_tensor.to(device).requires_grad_(True)\n",
        "\n",
        "# Convert the target embedding (emb_00001) to a tensor and move to device\n",
        "# Unsqueeze to add a batch dimension, matching the model output shape\n",
        "target_embedding_tensor = torch.tensor(emb_00001, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "optimizer = optim.Adam([random_image_tensor], lr=0.01)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "num_steps = 10000  # Try 500, 1000, or 5000\n",
        "\n",
        "print(\"Starting optimization...\")\n",
        "for i in range(num_steps):\n",
        "    # Clear old gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    normalized_image_input = torch.tanh(random_image_tensor * 2 - 1)\n",
        "    current_embedding = model(normalized_image_input)\n",
        "\n",
        "    loss = loss_fn(current_embedding, target_embedding_tensor)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"Step [{i+1}/{num_steps}], Loss: {loss.item():.6f}\")\n",
        "\n",
        "print(\"Optimization finished.\")"
      ],
      "metadata": {
        "id": "TpA2Z3jnQASW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_image_tensor = torch.tanh(random_image_tensor.detach().cpu().squeeze(0))\n",
        "final_image_tensor = (final_image_tensor * 0.5) + 0.5  # Rescale from [-1, 1] to [0, 1]\n",
        "\n",
        "final_image = transforms.ToPILImage()(final_image_tensor)\n",
        "final_image.save(\"generated_face.png\")\n",
        "print(\"Saved generated image to generated_face.png\")\n",
        "final_image.show()"
      ],
      "metadata": {
        "id": "A43HkFAuQZI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVLqrHgjPv3P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}